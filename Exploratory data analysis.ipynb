{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîπ Load and Verify Dataset Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "# Define dataset path\n",
    "dataset_path = r\"C:\\Users\\anujp\\Desktop\\Brain Tumor MRI Dataset\\archive\\Train\"\n",
    "\n",
    "# Get class names (subfolders)\n",
    "classes = [\"Glioma\", \"Meningioma\", \"Pituitary\", \"No Tumor\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print dataset structure\n",
    "for cls in classes:\n",
    "    img_count = len(os.listdir(f\"{dataset_path}/{cls}/images\"))\n",
    "    lbl_count = len(os.listdir(f\"{dataset_path}/{cls}/labels\"))\n",
    "    print(f\"üìÇ {cls}: {img_count} images, {lbl_count} labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîπ Count Images per Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count images in each class\n",
    "data_distribution = {cls: len(os.listdir(f\"{dataset_path}/{cls}/images\")) for cls in classes}\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(data_distribution.keys(), data_distribution.values(), color=[\"blue\", \"green\", \"red\", \"purple\"])\n",
    "plt.xlabel(\"Tumor Type\")\n",
    "plt.ylabel(\"Number of Images\")\n",
    "plt.title(\"Class Distribution\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîπ Visualize Random Images from Each Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to display sample images from each class\n",
    "def display_sample_images(class_name):\n",
    "    image_path = glob(f\"{dataset_path}/{class_name}/images/*.jpg\")[0]\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(class_name)\n",
    "    plt.show()\n",
    "\n",
    "# Display one image per class\n",
    "for cls in classes:\n",
    "    display_sample_images(cls)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üîπ Check Sample Bounding Box Annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read a sample annotation file\n",
    "sample_label = glob(f\"{dataset_path}/Glioma/labels/*.txt\")[0]\n",
    "\n",
    "with open(sample_label, \"r\") as file:\n",
    "    annotations = file.readlines()\n",
    "\n",
    "# Print the first few annotations\n",
    "print(\"\\nBounding Box Annotations (YOLO Format):\")\n",
    "print(\"\\n\".join(annotations[:5]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîπ Overlay Bounding Box on Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bounding_boxes(image_path, label_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    h, w, _ = img.shape\n",
    "\n",
    "    with open(label_path, \"r\") as file:\n",
    "        labels = file.readlines()\n",
    "\n",
    "    for label in labels:\n",
    "        class_id, x_center, y_center, width, height = map(float, label.split())\n",
    "        x1, y1 = int((x_center - width / 2) * w), int((y_center - height / 2) * h)\n",
    "        x2, y2 = int((x_center + width / 2) * w), int((y_center + height / 2) * h)\n",
    "\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "        cv2.putText(img, classes[int(class_id)], (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)\n",
    "\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "# Test with a sample image\n",
    "sample_img = glob(f\"{dataset_path}/Glioma/images/*.jpg\")[0]\n",
    "sample_lbl = sample_img.replace(\"images\", \"labels\").replace(\".jpg\", \".txt\")\n",
    "plot_bounding_boxes(sample_img, sample_lbl)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîπ Check for Missing Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_labels = []\n",
    "\n",
    "for cls in classes:\n",
    "    image_files = glob(f\"{dataset_path}/{cls}/images/*.jpg\")\n",
    "    for img in image_files:\n",
    "        label_path = img.replace(\"images\", \"labels\").replace(\".jpg\", \".txt\")\n",
    "        if not os.path.exists(label_path):\n",
    "            missing_labels.append(label_path)\n",
    "\n",
    "print(f\"‚ùå Missing Labels: {len(missing_labels)}\")\n",
    "if missing_labels:\n",
    "    print(\"Examples:\", missing_labels[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "# Define dataset path\n",
    "dataset_path = r\"C:\\Users\\anujp\\Desktop\\Brain Tumor MRI Dataset\\archive\\Train\"\n",
    "\n",
    "# Get all image paths\n",
    "image_paths = glob(f\"{dataset_path}/*/images/*.jpg\")\n",
    "\n",
    "# Dictionary to store unique image sizes\n",
    "unique_sizes = set()\n",
    "\n",
    "# Loop through images and get their sizes\n",
    "for img_path in image_paths:\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is not None:\n",
    "        unique_sizes.add(img.shape[:2])  # (Height, Width)\n",
    "\n",
    "# Print unique image sizes\n",
    "print(\"üìè Unique Image Sizes Found:\")\n",
    "for size in unique_sizes:\n",
    "    print(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé® Color Channels Found:\n",
      "{3}\n"
     ]
    }
   ],
   "source": [
    "# Check color channels\n",
    "color_channels = set()\n",
    "\n",
    "for img_path in image_paths:\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is not None:\n",
    "        color_channels.add(img.shape[2])  # Number of channels\n",
    "\n",
    "print(\"üé® Color Channels Found:\")\n",
    "print(color_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Collect pixel values\n",
    "pixel_values = []\n",
    "\n",
    "for img_path in image_paths:\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Read as grayscale\n",
    "    if img is not None:\n",
    "        pixel_values.extend(img.flatten())\n",
    "\n",
    "# Plot histogram of pixel values\n",
    "plt.hist(pixel_values, bins=50, color='blue', alpha=0.7)\n",
    "plt.title(\"Pixel Intensity Distribution\")\n",
    "plt.xlabel(\"Pixel Value\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get class names (subfolders)\n",
    "classes = [\"Glioma\", \"Meningioma\", \"Pituitary\", \"No Tumor\"]\n",
    "\n",
    "# Print class distribution\n",
    "for cls in classes:\n",
    "    img_count = len(os.listdir(f\"{dataset_path}/{cls}/images\"))\n",
    "    print(f\"üìÇ {cls}: {img_count} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check bounding box validity\n",
    "def is_bbox_valid(bbox, img_width, img_height):\n",
    "    x_center, y_center, width, height = bbox\n",
    "    x_min = x_center - width / 2\n",
    "    y_min = y_center - height / 2\n",
    "    x_max = x_center + width / 2\n",
    "    y_max = y_center + height / 2\n",
    "    return (0 <= x_min < x_max <= img_width) and (0 <= y_min < y_max <= img_height)\n",
    "\n",
    "invalid_bboxes = 0\n",
    "\n",
    "for cls in classes:\n",
    "    label_paths = glob(f\"{dataset_path}/{cls}/labels/*.txt\")\n",
    "    for label_path in label_paths:\n",
    "        with open(label_path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "        img_path = label_path.replace(\"labels\", \"images\").replace(\".txt\", \".jpg\")\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is not None:\n",
    "            img_height, img_width = img.shape[:2]\n",
    "            for line in lines:\n",
    "                bbox = list(map(float, line.strip().split()[1:]))  # Skip class_id\n",
    "                if not is_bbox_valid(bbox, img_width, img_height):\n",
    "                    invalid_bboxes += 1\n",
    "\n",
    "print(f\"‚ùå Invalid Bounding Boxes: {invalid_bboxes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from collections import defaultdict\n",
    "\n",
    "def analyze_image_shapes(image_dir, image_ext=\".jpg\"):\n",
    "    shapes_count = defaultdict(int)\n",
    "    channel_count = defaultdict(int)\n",
    "\n",
    "    for fname in os.listdir(image_dir):\n",
    "        if fname.endswith(image_ext):\n",
    "            path = os.path.join(image_dir, fname)\n",
    "            img = cv2.imread(path)\n",
    "            if img is not None:\n",
    "                h, w, c = img.shape\n",
    "                shapes_count[(h, w)] += 1\n",
    "                channel_count[c] += 1\n",
    "\n",
    "    print(\"Unique (height, width) combos and their frequencies:\")\n",
    "    for shape, count in shapes_count.items():\n",
    "        print(f\"  {shape}: {count}\")\n",
    "\n",
    "    print(\"\\nChannel distributions (e.g., 1=grayscale, 3=color):\")\n",
    "    for c, count in channel_count.items():\n",
    "        print(f\"  {c}-channel: {count}\")\n",
    "analyze_image_shapes(image_paths)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reinforcement_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
